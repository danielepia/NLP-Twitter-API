{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhyy23Rh/FZUq8EadF9ivL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielepia/NLP-Twitter-API/blob/main/Twitter_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install advertools"
      ],
      "metadata": {
        "id": "b-YlWj6ZX05B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfabf11-63fa-400a-e353-03eec29b4a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting advertools\n",
            "  Downloading advertools-0.13.1-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[K     |████████████████████████████████| 309 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from advertools) (0.4.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from advertools) (1.3.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from advertools) (6.0.1)\n",
            "Collecting twython\n",
            "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.6.1-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->advertools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->advertools) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->advertools) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->advertools) (1.15.0)\n",
            "Collecting pyOpenSSL>=16.2.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting queuelib>=1.4.2\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting zope.interface>=4.1.3\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 44.2 MB/s \n",
            "\u001b[?25hCollecting cssselect>=0.9.1\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting itemloaders>=1.0.1\n",
            "  Downloading itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
            "Collecting service-identity>=16.0.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting w3lib>=1.17.0\n",
            "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting PyDispatcher>=2.0.5\n",
            "  Downloading PyDispatcher-2.0.5.zip (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting protego>=0.1.15\n",
            "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (4.2.6)\n",
            "Collecting parsel>=1.5.0\n",
            "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting cryptography>=2.0\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 43.5 MB/s \n",
            "\u001b[?25hCollecting tldextract\n",
            "  Downloading tldextract-3.3.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting Twisted>=17.9.0\n",
            "  Downloading Twisted-22.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 35.9 MB/s \n",
            "\u001b[?25hCollecting itemadapter>=0.1.0\n",
            "  Downloading itemadapter-0.6.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->scrapy->advertools) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->scrapy->advertools) (2.21)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy->advertools) (21.4.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy->advertools) (0.2.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy->advertools) (4.2.0)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting incremental>=21.3.0\n",
            "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy->advertools) (2.10)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy->advertools) (3.7.0)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy->advertools) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython->advertools) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython->advertools) (3.2.0)\n",
            "Building wheels for collected packages: PyDispatcher\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-py3-none-any.whl size=11516 sha256=b74a1dc98be6ccefab758ea1114c7cd6961fa7ae0204b37e7e3846344b70734e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/18/21/3c6a732eaa69a339198e08bb63b7da2c45933a3428b29ec454\n",
            "Successfully built PyDispatcher\n",
            "Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, twython, scrapy, advertools\n",
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-22.4.0 advertools-0.13.1 constantly-15.1.0 cryptography-37.0.2 cssselect-1.1.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.6.0 itemloaders-1.0.4 jmespath-1.0.0 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.0.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.6.1 service-identity-21.1.0 tldextract-3.3.0 twython-3.9.1 w3lib-1.22.0 zope.interface-5.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "4oTJvjg9X5kC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d5d5e3-9e24-4f07-b3a1-e552d692ea01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAbDsibmyye8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import tweepy\n",
        "import advertools as adv\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TwitterClient(object):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        auth_params = {\n",
        "            'app_key': 'xxxx',\n",
        "            'app_secret': 'xxxx',\n",
        "            'oauth_token': 'xxxx-xxxx',\n",
        "            'oauth_token_secret': 'xxxx',\n",
        "            }\n",
        "  \n",
        "        adv.twitter.set_auth_params(**auth_params)\n",
        "  \n",
        "    def clean_tweet(self, tweet):\n",
        "\n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "  \n",
        "    def get_tweet_sentiment_comp(self, tweet):\n",
        "        analyser = SentimentIntensityAnalyzer()\n",
        "        analysis = analyser.polarity_scores(tweet)\n",
        "        val = analysis['compound']\n",
        "        return val\n",
        "\n",
        "    def get_tweet_sentiment(self, val):\n",
        "        if val > 0.05:\n",
        "            return 'positive'\n",
        "        elif val < -.05:\n",
        "            return 'negative'\n",
        "        else:\n",
        "            return 'neutral'\n",
        "\n",
        "\n",
        "    def get_tweets(self, user,field, count = 10):\n",
        "        alerts_list = {user:field}\n",
        "    \n",
        "        for keys,values in alerts_list.items():\n",
        "            df = adv.twitter.get_user_timeline(screen_name=keys,tweet_mode=\"extended\")\n",
        "            df = df[df['tweet_full_text'].str.contains(values,regex=True)]\n",
        " \n",
        "        tweets = []\n",
        "\n",
        "        for tweet in df['tweet_full_text']:\n",
        "            parsed_tweet = {}\n",
        "            parsed_tweet['text'] = tweet\n",
        "            val = self.get_tweet_sentiment_comp(tweet)\n",
        "            parsed_tweet['sentiment_comp'] = val\n",
        "            parsed_tweet['sentiment'] = self.get_tweet_sentiment(val)\n",
        "            tweets.append(parsed_tweet)\n",
        "        return tweets\n"
      ],
      "metadata": {
        "id": "Qj96cWCry4Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    api = TwitterClient()\n",
        "\n",
        "    tweets = api.get_tweets(user='FoxNews',field='', count = 10)\n",
        "    tweets_df = pd.DataFrame(tweets).sort_values('sentiment_comp')\n",
        "\n",
        "    print(tweets_df['sentiment'].value_counts()/tweets_df.shape[0])\n",
        "\n",
        "    # printing first 5 positive tweets\n",
        "    print(\"\\n\\nPositive tweets:\")\n",
        "    for i in tweets_df[tweets_df['sentiment']=='positive'].iloc[-5:]['text']:\n",
        "      print(i)\n",
        "\n",
        "    # printing first 5 negative tweets\n",
        "    print(\"\\n\\nNegative tweets:\")\n",
        "    for i in tweets_df[tweets_df['sentiment']=='negative'].iloc[:5]['text']:\n",
        "      print(i)  \n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3TEzVAty9mQ",
        "outputId": "5f7373e8-528f-4858-b544-7004b4031a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-26 11:56:26,578 | INFO | twitter.py:238 | wrapper | get_user_timeline | Requesting: count=200, max_id=None, screen_name=FoxNews, tweet_mode=extended\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative    0.42\n",
            "neutral     0.32\n",
            "positive    0.26\n",
            "Name: sentiment, dtype: float64\n",
            "\n",
            "\n",
            "Positive tweets:\n",
            "‘TOMORROW’S NOT PROMISED’: Xavier Lopez’s uncle describes his nephew to Fox News Digital, urges everyone to treasure their loved ones. https://t.co/rfMBLrKzNG https://t.co/8IW2H6FfJ3\n",
            "US flag-carrying 'Old Glory Relay' for The World Games kicks off with veterans, military supporters https://t.co/V1f8A5a6zv\n",
            "Queen Elizabeth was impressed by Kate Middleton’s adoration for Prince William despite royal status: author https://t.co/jyCwau9tQZ\n",
            "RT @foxweather: WOW! ⚡ \n",
            "\n",
            "A line of strong thunderstorms put on quite a display of lightning for passengers flying over the Gulf Coast on Sa…\n",
            "Mayorkas praises Border Patrol for response to Uvalde shooting, says heroism 'saved lives' https://t.co/ULaBKP5F1A\n",
            "\n",
            "\n",
            "Negative tweets:\n",
            "NYC subway shooting suspect charged with murder in 'unprovoked' death, uttered 'no phones' before attack: cops https://t.co/y9mAFZQl1D\n",
            "TRAGEDY IN TEXAS: @GovAbbott addresses community grappling with horrific mass shootings as victims are being identified. https://t.co/zLs5uWw4Ve https://t.co/D7WyGg44lx\n",
            "Man arrested after threatening mass violence at elementary school, authorities say https://t.co/ntpiPpBrW2\n",
            "'ONE OF THE WORST': Obama clobbered for linking school shooting to George Floyd's murder\n",
            "\n",
            "https://t.co/rmeFltME6m https://t.co/bVCU84Va0G\n",
            "‘FAMILIES BROKEN APART’: Texas Governor Greg Abbott revealed deputy sheriff lost his daughter during the tragedy in Uvalde.  https://t.co/QnbyMOFxNV https://t.co/jimDQaGpWV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "btqfi7D-yE7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}